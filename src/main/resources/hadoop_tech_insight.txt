offset=14
第1章 阅读源代码前的准备@2
1.1 准备源代码学习环境@2
1.1.1 基础软件下载@2
1.1.2 如何准备 Windows 环境@3
1.1.3 如何准备 Linux 环境@6
1.2 获取 Hadoop 源代码@7
1.3 搭建 Hadoop 源代码阅读环境@8
1.3.1 创建 Hadoop 工程@8
1.3.2 Hadoop 源代码阅读技巧@9
1.4 Hadoop 源代码组织结构@10
1.5 Hadoop 初体验@13
1.5.1 启动 Hadoop@13
1.5.2 Hadoop Shell 介绍@15
1.5.3 Hadoop Eclipse 插件介绍@15
1.6 编译及调试 Hadoop 源代码@19
1.6.1 编译 Hadoop 源代码@19
1.6.2 调试 Hadoop 源代码@20
1.7 小结@23
第2章 MapReduce 设计理念与基本架构@24
2.1 Hadoop 发展史@24
2.1.1 Hadoop 产生背景@24
2.1.2 Apache Hadoop 新版本的特性@25
2.1.3 Hadoop 版本变迁@26
2.2 Hadoop MapReduce 设计目标@28
2.3 MapReduce 编程模型概述@29
2.3.1 MapReduce 编程模型简介@29
2.3.2 MapReduce 编程实例@31
2.4 Hadoop 基本架构@32
2.4.1 HDFS 架构@33
2.4.2 Hadoop MapReduce 架构@34
2.5 Hadoop MapReduce 作业的生命周期@36
2.6 小结@38
第3章 MapReduce 编程模型@40
3.1 MapReduce 编程模型概述@40
3.1.1 MapReduce 编程接口体系结构@40
3.1.2 新旧 MapReduce API 比较@41
3.2 MapReduce API 基本概念@42
3.2.1 序列化@42
3.2.2 Reporter 参数@43
3.2.3 回调机制@43
3.3 Java API 解析@44
3.3.1 作业配置与提交@44
3.3.2 InputFormat 接口的设计与实现@48
3.3.3 OutputFormat 接口的设计与实现@53
3.3.4 Mapper 与 Reducer 解析@55
3.3.5 Partitioner 接口的设计与实现@59
3.4 非 Java API 解析@61
3.4.1 Hadoop Streaming 的实现原理@61
3.4.2 Hadoop Pipes 的实现原理@64
3.5 Hadoop 工作流@67
3.5.1 JobControl 的实现原理@67
3.5.2 ChainMapper/ChainReducer 的实现原理@69
3.5.3 Hadoop 工作流引擎@71
3.6 小结@73
第4章 Hadoop RPC 框架解析@76
4.1 Hadoop RPC 框架概述@76
4.2 Java 基础知识@77
4.2.1 Java 反射机制与动态代理@78
4.2.2 Java 网络编程@80
4.2.3 Java NIO@82
4.3 Hadoop RPC 基本框架分析@89
4.3.1 RPC 基本概念@89
4.3.2 Hadoop RPC 基本框架@91
4.3.3 集成其他开源 RPC 框架@98
4.4 MapReduce 通信协议分析@100
4.4.1 MapReduce 通信协议概述@100
4.4.2 JobSubmissionProtocol 通信协议@102
4.4.3 InterTrackerProtocol 通信协议@102
4.4.4 TaskUmbilicalProtocol 通信协议@103
4.4.5 其他通信协议@104
4.5 小结@106
第5章 作业提交与初始化过程分析@107
5.1 作业提交与初始化概述@107
5.2 作业提交过程详解@108
5.2.1 执行 Shell 命令@108
5.2.2 作业文件上传@109
5.2.3 产生 InputSplit 文件@111
5.2.4 作业提交到 JobTracker@113
5.3 作业初始化过程详解@115
5.4 Hadoop DistributedCache 原理分析@117
5.4.1 使用方法介绍@118
5.4.2 工作原理分析@120
5.5 小结@122
第6章 JobTracker 内部实现剖析@123
6.1 JobTracker 概述@123
6.2 JobTracker 启动过程分析@125
6.2.1 JobTracker 启动过程概述@125
6.2.2 重要对象初始化@125
6.2.3 各种线程功能@128
6.2.4 作业恢复@129
6.3 心跳接收与应答@129
6.3.1 更新状态@131
6.3.2 下达命令@131
6.4 Job 和 Task 运行时信息维护@134
6.4.1 作业描述模型@134
6.4.2 JobInProgress@136
6.4.3 TaskInProgress@137
6.4.4 作业和任务状态转换图@139
6.5 容错机制@141
6.5.1 JobTracker 容错@141
6.5.2 TaskTracker 容错@142
6.5.3 Job/Task 容错@145
6.5.4 Record 容错@147
6.5.5 磁盘容错@151
6.6 任务推测执行原理@152
6.6.1 计算模型假设@153
6.6.2 1.0.0 版本的算法@153
6.6.3 0.21.0 版本的算法@154
6.6.4 2.0 版本的算法@156
6.7 Hadoop 资源管理@157
6.7.1 任务调度框架分析@159
6.7.2 任务选择策略分析@162
6.7.3 FIFO 调度器分析@164
6.7.4 Hadoop 资源管理优化@165
6.8 小结@168
第7章 TaskTracker 内部实现剖析@169
7.1 TaskTracker 概述@169
7.2 TaskTracker 启动过程分析@170
7.2.1 重要变量初始化@171
7.2.2 重要对象初始化@171
7.2.3 连接 JobTracker@172
7.3 心跳机制@172
7.3.1 单次心跳发送@172
7.3.2 状态发送@175
7.3.3 命令执行@178
7.4 TaskTracker 行为分析@179
7.4.1 启动新任务@179
7.4.2 提交任务@179
7.4.3 杀死任务@181
7.4.4 杀死作业@182
7.4.5 重新初始化@184
7.5 作业目录管理@184
7.6 启动新任务@186
7.6.1 任务启动过程分析@186
7.6.2 资源隔离机制@193
7.7 小结@195
第8章 Task 运行过程分析@196
8.1 Task 运行过程概述@196
8.2 基本数据结构和算法@197
8.2.1 IFile 存储格式@197
8.2.2 排序@198
8.2.3 Reporter@201
8.3 Map Task 内部实现@204
8.3.1 Map Task 整体流程@204
8.3.2 Collect 过程分析@205
8.3.3 Spill 过程分析@213
8.3.4 Combine 过程分析@214
8.4 Reduce Task 内部实现@214
8.4.1 Reduce Task 整体流程@215
8.4.2 Shuffle 和 Merge 阶段分析@215
8.4.3 Sort 和 Reduce 阶段分析@218
8.5 Map/Reduce Task 优化@219
8.5.1 参数调优@219
8.5.2 系统优化@220
8.6 小结@224
第9章 Hadoop 性能调优@228
9.1 概述@228
9.2 从管理员角度进行调优@229
9.2.1 硬件选择@229
9.2.2 操作系统参数调优@229
9.2.3 JVM 参数调优@230
9.2.4 Hadoop 参数调优@230
9.3 从用户角度进行调优@235
9.3.1 应用程序编写规范@235
9.3.2 作业级别参数调优@235
9.3.3 任务级别参数调优@239
9.4 小结@240
第10章 Hadoop 多用户作业调度器@241
10.1 多用户调度器产生背景@241
10.2 HOD@242
10.2.1 Torque 资源管理器@242
10.2.2 HOD 作业调度@243
10.3 Hadoop 队列管理机制@245
10.4 Capacity Scheduler 实现@246
10.4.1 Capacity Scheduler 功能介绍@247
10.4.2 Capacity Scheduler 实现@249
10.4.3 多层队列调度@254
10.5 Fair Scheduler 实现@255
10.5.1 Fair Scheduler 功能介绍@255
10.5.2 Fair Scheduler 实现@258
10.5.3 Fair Scheduler 与 Capacity Scheduler 对比@263
10.6 其他 Hadoop 调度器介绍@264
10.7 小结@265
第11章 Hadoop 安全机制@266
11.1 Hadoop 安全机制概述@266
11.1.1 Hadoop 面临的安全问题@266
11.1.2 Hadoop 对安全方面的需求@267
11.1.3 Hadoop 安全设计基本原则@267
11.2 基础知识@268
11.2.1 安全认证机制@268
11.2.2 Kerberos 介绍@270
11.3 Hadoop 安全机制实现@273
11.3.1 RPC@273
11.3.2 HDFS@276
11.3.3 MapReduce@278
11.3.4 上层服务@280
11.4 应用场景总结@281
11.4.1 文件存取@281
11.4.2 作业提交与运行@282
11.4.3 上层中间件访问 Hadoop@282
11.5 小结@283
第12章 下一代 MapReduce 框架@284
12.1 第一代 MapReduce 框架的局限性@284
12.2 下一代 MapReduce 框架概述@284
12.2.1 基本设计思想@284
12.2.2 资源统一管理平台@286
12.3 Apache YARN@287
12.3.1 Apache YARN 基本框架@287
12.3.2 Apache YARN 工作流程@290
12.3.3 Apache YARN 设计细节@291
12.3.4 MapReduce 与 YARN 结合@294
12.4 Facebook Corona@298
12.4.1 Facebook Corona 基本框架@298
12.4.2 Facebook Corona 工作流程@300
12.4.3 YARN 与 Corona 对比@303
12.5 Apache Mesos@304
12.5.1 Apache Mesos 基本框架@304
12.5.2 Apache Mesos 资源分配@305
12.5.3 MapReduce 与 Mesos 结合@307
12.6 小结@309
附录 A 安装 Hadoop 过程中可能存在的问题及解决方案@310
附录 B Hadoop 默认 HTTP 端口号以及 HTTP 地址@312
参考资料@313
